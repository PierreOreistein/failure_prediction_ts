{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Pierre Oreistein\n",
    "# Description inspired by: https://towardsdatascience.com/predictive-maintenance-of-turbofan-engines-ec54a083127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling Packages\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning Packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prevent unecessary warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\", \".*`should_run_async`.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unecessary_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove unecessary columns.\"\"\"\n",
    "    # Load columns to drop defined in params\n",
    "    columns_to_drop_l = context.params[\"columns_to_drop\"]\n",
    "    \n",
    "    # Drop the columns\n",
    "    df.drop(columns_to_drop_l, inplace=True, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remaining_useful_life(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add remaining useful life to df.\"\"\"\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit_df = df.groupby(by=\"unit_nb\")\n",
    "    max_cycle_s = grouped_by_unit_df[\"time\"].max()\n",
    "\n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_df = df.merge(\n",
    "        max_cycle_s.to_frame(name=\"max_cycle\"), left_on=\"unit_nb\", right_index=True\n",
    "    )\n",
    "\n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life_s = result_df[\"max_cycle\"] - result_df[\"time\"]\n",
    "    result_df[\"RUL\"] = remaining_useful_life_s\n",
    "\n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_df = result_df.drop(\"max_cycle\", axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_X_train(X_train_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses the training data.\n",
    "\n",
    "    Args:\n",
    "        X_train_raw: Raw data.\n",
    "    Returns:\n",
    "        Preprocessed data, by dropping unecessary columns and adding the Reamining Useful Life (RUL).\n",
    "    \"\"\"    \n",
    "    # Add RUL (target) to training set\n",
    "    train_df = add_remaining_useful_life(X_train_raw)\n",
    "    \n",
    "    # Drop unecessary features\n",
    "    train_df = drop_unecessary_columns(train_df)\n",
    "    \n",
    "    # Scale the sensors values\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaling_columns = [col_name for col_name in train_df.columns if col_name not in [\"RUL\"]]\n",
    "    train_df[scaling_columns] = scaler.fit_transform(train_df[scaling_columns])\n",
    "    \n",
    "    # Save the StandardScaler\n",
    "    catalog.save(name=\"StandardScaler\", data=scaler)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "X_train_df = catalog.load(\"X_train_raw\")\n",
    "\n",
    "# Preprocess the training dataset and save it\n",
    "train_df = preprocess_X_train(X_train_df)\n",
    "\n",
    "# Save the training dataset\n",
    "catalog.save(\"train_preprocessed_df\", train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_X_test(X_test_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses the testing data.\n",
    "\n",
    "    Args:\n",
    "        X_test_raw: Raw data.\n",
    "    Returns:\n",
    "        Preprocessed data, by dropping unecessary columns.\n",
    "    \"\"\"\n",
    "    # Keep only the last timestamp\n",
    "    X_test_df = X_test_raw.groupby('unit_nb').last().reset_index()\n",
    "    \n",
    "    # Drop unecessary features\n",
    "    X_test_df = drop_unecessary_columns(X_test_df)\n",
    "    \n",
    "    # Scale the sensors values\n",
    "    scaler = catalog.load(\"StandardScaler\")\n",
    "    X_test = scaler.transform(X_test_df)\n",
    "    X_test_df = pd.DataFrame(\n",
    "        X_test,\n",
    "        columns=X_test_df.columns,\n",
    "        index=X_test_df.index\n",
    "    )\n",
    "    return X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "X_test_df = catalog.load(\"X_test_raw\")\n",
    "\n",
    "# Preprocess the training dataset and save it\n",
    "X_test_df = preprocess_X_test(X_test_df)\n",
    "\n",
    "# Save the training dataset\n",
    "catalog.save(\"X_test_preprocessed_df\", X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "TurboFanFailurePrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
