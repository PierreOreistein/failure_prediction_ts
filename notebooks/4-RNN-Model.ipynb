{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12027ca",
   "metadata": {},
   "source": [
    "# Weibull RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1472460b",
   "metadata": {},
   "source": [
    "# 1 - Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53adde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Pierre Oreistein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae9e1c",
   "metadata": {},
   "source": [
    "# 2 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a611ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math Packages\n",
    "import numpy as np\n",
    "\n",
    "# Data Handling Packages\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, History, TerminateOnNaN\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "# Attention\n",
    "#from attention import attention_3d_block\n",
    "\n",
    "# Prevent unecessary warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\", \".*`should_run_async`.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377a61a",
   "metadata": {},
   "source": [
    "# 3 - RNN Model: WTTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404df68b",
   "metadata": {},
   "source": [
    "## 3.1 - Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is a GPU available?\", bool(len(tf.config.list_physical_devices('GPU'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589d8cc",
   "metadata": {},
   "source": [
    "## 3.2 - Custom Loss and Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12acf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipping_activation(bbeta: tf.Tensor, name: str=None) -> tf.Tensor:\n",
    "    \"\"\"Relu activation with clipping to avoid exploding parameters\n",
    "\n",
    "       Args:\n",
    "        bbeta is a (samples, 2) tensor containing the parameters b and beta of the Weibull distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply a relu activation\n",
    "    b = K.clip(relu(bbeta[:, 0]), 10e-5, 10e5)\n",
    "    beta = K.clip(relu(bbeta[:, 1]), 10e-5, 10e5)\n",
    "\n",
    "    # Reshape the two parameters to vectors\n",
    "    b = K.reshape(b, (K.shape(b)[0], 1))\n",
    "    beta = K.reshape(beta, (K.shape(beta)[0], 1))\n",
    "\n",
    "    return K.concatenate((b, beta), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba21392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true: tf.Tensor, bbeta_pred: tf.Tensor, name: str=None) -> tf.Tensor:\n",
    "    \"\"\" Customn loss for the maximising the Weibull log-likelihood\n",
    "\n",
    "        Args:\n",
    "            y_true: tensor with last dimension having length 2\n",
    "                with y_true[:,0] = time to event,\n",
    "                     y_true[:,1] = indicator of not censored\n",
    "\n",
    "            y_pred: tensor with last dimension having length 2 \n",
    "                with y_pred[:,0] = alpha,\n",
    "                     y_pred[:,1] = beta\n",
    "\n",
    "        Returns:\n",
    "            A positive `Tensor` of same shape as input\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract b, beta, y, u\n",
    "    b = bbeta_pred[:, 0]\n",
    "    beta = bbeta_pred[:, 1]\n",
    "    y = y_true[:, 0]\n",
    "    u = y_true[:, 1]\n",
    "\n",
    "    # Compute the log-likelihood for u == 1 and u == 0\n",
    "    hazard_u_1 = b * K.exp(beta * K.log(y)) - (beta - 1) * K.log(y) - K.log(beta) - K.log(b) # uncensored data\n",
    "    hazard_u_0 = - K.log(1 - K.exp(-b * K.exp(beta * K.log(y)))) # censored data\n",
    "    \n",
    "    loglikelihoods = u * hazard_u_1 + (1 - u) * hazard_u_0\n",
    "    loss = K.mean(loglikelihoods)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f178ad0d",
   "metadata": {},
   "source": [
    "## 3.3 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f049dd6",
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(nb_features: int = 15) -> tf.keras.Model:\n",
    "    \"\"\"Create RNN model\"\"\"\n",
    "    # Redifine epsilon\n",
    "    K.set_epsilon(1e-20)\n",
    "\n",
    "    # Callbacks\n",
    "    nanterminator = TerminateOnNaN()\n",
    "    callbacks = [nanterminator]\n",
    "\n",
    "    # Metrics\n",
    "    metrics = []\n",
    "\n",
    "    # Start building our model\n",
    "    i = Input(batch_shape=(None, 1, nb_features))\n",
    "    x = LSTM(10, return_sequences=True, unroll=True)(i) # returns a sequence of vectors of dimension 32\n",
    "    x = attention_3d_block(x)\n",
    "    x = Dense(2, activation=clipping_activation)(x)\n",
    "    model = Model(inputs=[i], outputs=[x])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss=custom_loss, metrics=metrics)\n",
    "\n",
    "    # Display the model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba9167",
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "def train_rnn_model(model: tf.keras.Model, train_df: pd.DataFrame) -> tf.keras.Model:\n",
    "    \"\"\"Train the baseline model.\"\"\"\n",
    "    # Extract X and Y\n",
    "    X_train_df = train_df\n",
    "    y_train_df = X_train_df.pop('RUL')\n",
    "    \n",
    "    # Train the baseline model\n",
    "    model.fit(\n",
    "        X_train_df,\n",
    "        y_train_df,\n",
    "        epochs=DEEP_LEARNING_PARAMS_DCT[\"epoch\"],\n",
    "        batch_size=DEEP_LEARNING_PARAMS_DCT[\"batch-size\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Deep Learning params\n",
    "DEEP_LEARNING_PARAMS_DCT = context.params[\"deep-learning-parameters\"]\n",
    "DEEP_LEARNING_PARAMS_DCT = {k: v for d in DEEP_LEARNING_PARAMS_DCT for k, v in d.items()}\n",
    "\n",
    "# Load the training dataset\n",
    "train_df = catalog.load(\"train_preprocessed_df\")\n",
    "\n",
    "# Create the baseline model\n",
    "nb_features = int(DEEP_LEARNING_PARAMS_DCT[\"nb_features\"])\n",
    "model = create_rnn_model(nb_features=nb_features)\n",
    "\n",
    "# Train the baseline model\n",
    "model = train_rnn_model(model=model, train_df=train_df)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "TurboFanFailurePrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
