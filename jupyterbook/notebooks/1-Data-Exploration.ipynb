{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Pierre Oreistein\n",
    "# Description inspired by: https://towardsdatascience.com/predictive-maintenance-of-turbofan-engines-ec54a083127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math Packages\n",
    "import numpy as np\n",
    "\n",
    "# Statistical packages\n",
    "from scipy.stats import exponweib, weibull_max, weibull_min\n",
    "\n",
    "# Graphics Packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Data Handling Packages\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning Packages\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Prevent unecessary warnings\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\", \".*`should_run_async`.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The engines operate normally in the beginning but develop a fault over time. For the training sets, the engines are run to failure, while in the test sets the time series end ‘sometime’ before failure. The goal is to predict the Remaining Useful Life (RUL) of each turbofan engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets include simulations of multiple turbofan engines over time, each row contains the following information:\n",
    "1. Engine unit number\n",
    "2. Time, in cycles\n",
    "3. Three operational settings\n",
    "4. 21 sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = catalog.load(\"X_train_raw\")\n",
    "\n",
    "# Display train_df\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = catalog.load(\"X_test_raw\")\n",
    "\n",
    "# Display train_df\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = catalog.load(\"y_test_raw\")\n",
    "\n",
    "# Display train_df\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Check Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the operating mode. We should only observe 1\n",
    "X_train_df[[\"setting_1\", \"setting_2\", \"setting_3\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the standard deviations of settings 1 and 2, they aren’t completely stable. The fluctuations are so small however, that no other operating conditions can be identified. As there is only one operating mode, we will discard these three features in our final training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe sensors\n",
    "SENSORS_NAME_L = [f\"s_{i}\" for i in range(20)]\n",
    "\n",
    "# Check the sensors data (variablity mainly)\n",
    "X_train_df[SENSORS_NAME_L].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the standard deviation it’s clear sensors 1, 10, 18 and 19 do not fluctuate at all, these can be safely discarded as they hold no useful information. Inspecting the quantiles indicates sensors 5, 6 and 16 have little fluctuation and require further inspection. Sensors 9 and 14 have the highest fluctuation, however this does not mean the other sensors can’t hold valuable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remaining_useful_life(df):\n",
    "    \"\"\"Add remaining useful life to df.\"\"\"\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit_df = df.groupby(by=\"unit_nb\")\n",
    "    max_cycle_s = grouped_by_unit_df[\"time\"].max()\n",
    "\n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_df = df.merge(\n",
    "        max_cycle_s.to_frame(name=\"max_cycle\"), left_on=\"unit_nb\", right_index=True\n",
    "    )\n",
    "\n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life_s = result_df[\"max_cycle\"] - result_df[\"time\"]\n",
    "    result_df[\"RUL\"] = remaining_useful_life_s\n",
    "\n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_df = result_df.drop(\"max_cycle\", axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add remaining useful life\n",
    "train_df = add_remaining_useful_life(X_train_df)\n",
    "\n",
    "# Display Resulting DataFrame\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Visualise Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor(df: pd.DataFrame, sensor_name: str, scaling: str = False) -> None:\n",
    "    \"\"\"Plot the sensor value over time for the different units/engines.\"\"\"\n",
    "    # Initialisation of the figure\n",
    "    plt.figure(figsize=(13, 5))\n",
    "\n",
    "    # Subsample some units for faster display\n",
    "    grouped_df = df.groupby(\"unit_nb\")\n",
    "    for unit, g_df in grouped_df:\n",
    "        if unit % 10 == 0:  # only plot every 10th unit_nr\n",
    "\n",
    "            # Scaling of the data\n",
    "            if scaling:\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                g_df[sensor_name] = scaler.fit_transform(\n",
    "                    g_df[sensor_name].values.reshape(-1, 1)\n",
    "                )\n",
    "\n",
    "            plt.plot(\"RUL\", sensor_name, data=g_df)\n",
    "\n",
    "    # Reverse the x-axis so RUL counts down to zero\n",
    "    plt.xlim(275, 0)\n",
    "\n",
    "    # Customize axis and title\n",
    "    plt.xticks(np.arange(0, 275, 25))\n",
    "    plt.ylabel(sensor_name)\n",
    "    plt.xlabel(\"Remaining Use fulLife\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 - Discarded sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_0\", \"s_4\", \"s_9\", \"s_15\", \"s_17\", \"s_18\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of sensors 0, 4, 9, 15, 17 and 18 looks similar, the flat line indicates the sensors hold no useful information, which reconfirms our conclusion from the descriptive statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_0\", \"s_4\", \"s_9\", \"s_15\", \"s_17\", \"s_18\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name, scaling=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with scaling, the sensors 0, 4, 9, 15, 17 and 18 does not seem to contain useful information. We will discard them for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_5\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name, scaling=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor readings of sensor 6 peak downwards at times but there doesn’t seem to be a clear relation to the decreasing RUL. We will remove this sensor from our final training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 - Sensors preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_1\", \"s_2\", \"s_3\", \"s_7\", \"s_10\", \"s_12\", \"s_14\", \"s_16\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name, scaling=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor 1 shows a rising trend, a similar pattern can be seen for sensors 1, 2, 3, 7, 10, 12, 14 and 16. We will keep these features in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_6\", \"s_11\", \"s_19\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name, scaling=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor 6 shows a declining trend, which can also be seen in sensors 12, 19 and 11. We will keep these sensors in our final training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different sensor time series\n",
    "for sensor_name in [\"s_8\"]:\n",
    "\n",
    "    print(f\"----- Sensor {sensor_name} -----\")\n",
    "    plot_sensor(df=train_df, sensor_name=sensor_name, scaling=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor 8 has a similar pattern as sensor 13. We will keep its information for our final training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Traget Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Remaining Useful Life Histogram of our training set\n",
    "max_rul_df = train_df[[\"unit_nb\", \"RUL\"]].groupby(\"unit_nb\").max().reset_index()\n",
    "max_rul_df[\"RUL\"].hist(bins=10, figsize=(15, 7))\n",
    "\n",
    "plt.xlabel(\"RUL\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this distribution to a Weibull distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's rescale the rul\n",
    "rul_a = max_rul_df[\"RUL\"].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "rul_a = scaler.fit_transform(rul_a)\n",
    "\n",
    "# Let's display the best fitted Weibull distribution vs the RUL observed\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.hist(rul_a, bins=10, density=True, alpha=0.8)\n",
    "plt.scatter(\n",
    "    rul_a, weibull_max.pdf(rul_a, *weibull_max.fit(rul_a)), c=\"red\", zorder=10\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notive that the best Weibull fit well the dataset. It is therefore legitimate to try to fit a Weibull distribution on our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TurboFanFailurePrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
